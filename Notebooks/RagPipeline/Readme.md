# ü§ñ RAGPipeline ‚Äî Busca e Resposta Baseada em PDFs

## üìò Descri√ß√£o Geral
O arquivo implementa a classe **`RAGPipeline`**, que encapsula o **retriever + LLM** para fornecer respostas **precisas e contextualizadas** a perguntas sobre documentos PDF indexados.  
Ele permite **busca por CPF ou CNPJ**, utilizando metadados dos documentos (`cpf_contratado`, `cnpj_contratado`), garantindo respostas **rigorosas e confi√°veis**.


Autor: Kevin

---

## ‚öôÔ∏è Classe `RAGPipeline`

### üîπ Prop√≥sito
- Conectar **vectorstore Pinecone** ao modelo de linguagem (LLM) da OpenAI.
- Permitir consultas **sem√¢nticas e filtradas por CPF/CNPJ**.
- Fornecer respostas **fidelidade absoluta ao texto do contrato**.

### üîπ Atributos Principais
- `pinecone`: cliente Pinecone para acesso ao vectorstore.
- `embeddings`: embeddings OpenAI para vetoriza√ß√£o do texto.
- `vectorstore`: PineconeVectorStore contendo os chunks indexados.
- `llm`: modelo ChatOpenAI para gera√ß√£o de respostas.
- `prompt_template`: prompt rigoroso com regras de fidelidade, c√°lculo de prazos e an√°lise l√≥gica.

---

### üîπ M√©todo `answer(search_key: str, question: str, k: int = 20) -> dict`
- **Fun√ß√£o:** retorna um dicion√°rio com a resposta da LLM e os trechos do contexto utilizados.
- **Par√¢metros:**
  - `search_key`: CPF ou CNPJ para filtrar documentos.
  - `question`: pergunta do usu√°rio.
  - `k`: n√∫mero de chunks relevantes a considerar (default: 20).
- **Retorno:**
```python
{
    "answer": "Resposta gerada pela LLM",
    "context": [ "chunk1", "chunk2", ... ]
}
```

- **Processo Interno:**
  1. Normaliza a chave (CPF/CNPJ) usando `TextProcessor`.
  2. Cria um retriever filtrando por `cpf_contratado` e `cnpj_contratado`.
  3. Recupera os documentos relevantes (`k` chunks).
  4. Gera resposta via LLM usando **prompt rigoroso**.
  5. Retorna a resposta e os snippets de contexto.

---

### üîπ Prompt Template
O prompt define regras de **rigor absoluto**:

- Fidelidade estrita √†s informa√ß√µes do contrato.
- Exaust√£o de listas e condi√ß√µes.
- C√°lculo de prazos de penalidades.
- Infer√™ncia de nega√ß√£o quando aplic√°vel.
- Respostas negativas apenas quando n√£o h√° base no documento.

---

### üîπ Observa√ß√µes
- Logs detalhados registram:
  - Chunks recuperados
  - Metadados de cada chunk
  - Contexto enviado √† LLM
  - Pergunta e resposta gerada


---

## ‚úÖ Status
- Classe `RAGPipeline` implementada.
- Busca sem√¢ntica filtrada por CPF/CNPJ funcional.
- Respostas geradas com alta fidelidade ao texto dos PDFs.
